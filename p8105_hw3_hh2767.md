p8105\_hw3\_hh2767
================
Haoran Hu, hh2767
2018-10-09

Problem 1
=========

Data cleaning
-------------

``` r
brfss = janitor::clean_names(brfss_smart2010)
colnames(brfss)[2] = "location_abbr"
colnames(brfss)[3] = "location_desc"
brfss = filter(brfss, topic == "Overall Health") %>% 
   mutate(response = factor(response, levels = c("Excellent", "Very good", "Good", "Fair", "Poor"))) %>%
  arrange(response)
```

Answering questions
-------------------

### question 1

``` r
  filter(brfss, year == 2002) %>% 
  group_by(location_abbr) %>% 
  summarize(n_location = n_distinct(location_desc)) %>% 
  filter(n_location == 7)
```

    ## # A tibble: 3 x 2
    ##   location_abbr n_location
    ##   <chr>              <int>
    ## 1 CT                     7
    ## 2 FL                     7
    ## 3 NC                     7

From the result above, we know that in 2002, Connecticut, Florida, and North Carolina were observed at 7 locations.

### question 2

``` r
brfss %>% 
  group_by(year, location_abbr) %>% 
  summarize(n_location = n_distinct(location_desc)) %>% 
  ggplot(aes(x = year, y = n_location, color = location_abbr)) +
  labs(title = "number of locations observed", y = "number of locations") +
  geom_line() + geom_point() +
  theme_bw() + viridis::scale_color_viridis(
    name = "Location", 
    discrete = TRUE
  )
```

<img src="p8105_hw3_hh2767_files/figure-markdown_github/unnamed-chunk-3-1.png" width="90%" />

The plot above is a “spaghetti plot” that shows the number of locations in each state from 2002 to 2010. From the plot, we can see that in most of the states, number of locations observed is relative stable, with a little fluctuation. However, there are several states that have wide fluctuation, such as Florida.

### question 3

``` r
  brfss %>% 
  filter(location_abbr == "NY" & response == "Excellent") %>% 
  filter(year %in% c("2002", "2006", "2010")) %>% 
  group_by(year) %>% 
  summarize(`mean of prop. of "excellent" response` = round(mean(data_value, na.rm = TRUE),2), `sd of prop. of "excellent" response` = round(sd(data_value, na.rm = TRUE),2)) %>% 
  mutate(state = "NY") %>% 
  select(state, everything()) %>% 
  knitr::kable()
```

| state |  year|  mean of prop. of "excellent" response|  sd of prop. of "excellent" response|
|:------|-----:|--------------------------------------:|------------------------------------:|
| NY    |  2002|                                  24.04|                                 4.49|
| NY    |  2006|                                  22.53|                                 4.00|
| NY    |  2010|                                  22.70|                                 3.57|

The table is created as the requeste of the question. According to the table, we can see that the mean of the proportion of "excellent" response remains stable, while its standard deviation shows a slight trend of decreasing.

### question 4

``` r
theme_set(theme_bw())
brfss %>% 
  group_by(year, location_abbr, response) %>% 
  summarize(mean_prop = mean(data_value, na.rm = TRUE), sample_size = sum(sample_size)) %>% 
  ggplot(aes(x = year, y = mean_prop, color = location_abbr)) + geom_point(aes(size = sample_size), alpha = .5) + geom_smooth(se = FALSE) + labs(title = "proportion of each response in each state") + 
  facet_grid(~ response) +  viridis::scale_color_viridis(
    name = "Location", 
    discrete = TRUE
  )
```

    ## `geom_smooth()` using method = 'loess' and formula 'y ~ x'

<img src="p8105_hw3_hh2767_files/figure-markdown_github/unnamed-chunk-5-1.png" width="90%" />

The figure above is created as request of the question.The figure shows that the majority of people in each state responded "Excellent", "Very good", or "Good". What is interesting is that in each state, the proportion of each response is largely the same. In addition, the proportion of each response remains stable over the years.

Problem 2
=========

### question 1

``` r
 count = instacart %>% 
  count(aisle) %>% 
   arrange(-n)
```

There are 134 aisles, and "fresh vegetables" is ordered for the most times.

### question 2

First, in order to arrange the aisles according to the frequency that they are ordered when making the graph, I need to first turn the aisles in to ordered factor variables.

``` r
count$aisle = factor(count$aisle, levels = count$aisle)
```

Then, I can begin to make the graph.

``` r
order_over10k = ggplot(filter(count, n >= 10000), aes(x = aisle, y = n, fill = aisle)) + 
  geom_col() +  
  theme(legend.position = "bottom") + 
  scale_x_discrete(breaks = NULL) + 
  scale_y_continuous( limits = c(0, 160000)) + 
  labs(title = "More than 10000 items ordered", y = "number of orders") + 
  viridis::scale_fill_viridis(option = "virids", discrete = TRUE)

order_3k_10K = ggplot(filter(count, n >= 3000 & n < 10000), aes(x = aisle, y = n, fill = aisle)) + 
  geom_col() +  
  theme(legend.position = "bottom") + 
  scale_x_discrete(breaks = NULL) + 
  labs(title = "3000 to 10000 items ordered", y = "number of orders") + 
  viridis::scale_fill_viridis(option = "virids", discrete = TRUE)

ordre_less3k = ggplot(filter(count, n < 3000), aes(x = aisle, y = n, fill = aisle)) + 
  geom_col() +  
  theme(legend.position = "bottom") + 
  scale_x_discrete(breaks = NULL) + 
  labs(title = "Less than 3000 items ordered", y = "number of orders") +
  viridis::scale_fill_viridis(option = "virids", discrete = TRUE)

(order_over10k + order_3k_10K) / ordre_less3k
```

    ## Warning in viridisLite::viridis(n, alpha, begin, end, direction, option):
    ## Option 'virids' does not exist. Defaulting to 'viridis'.

    ## Warning in viridisLite::viridis(n, alpha, begin, end, direction, option):
    ## Option 'virids' does not exist. Defaulting to 'viridis'.

    ## Warning in viridisLite::viridis(n, alpha, begin, end, direction, option):
    ## Option 'virids' does not exist. Defaulting to 'viridis'.

<img src="p8105_hw3_hh2767_files/figure-markdown_github/unnamed-chunk-8-1.png" width="90%" style="display: block; margin: auto;" />

We can also make the graph in the following way.

``` r
ggplot(filter(count, n >= 10000), aes(x = aisle, y = n)) + 
  geom_col(fill = "lightcoral", color = "navy") +  
  theme(legend.position = "bottom") + 
  scale_y_continuous( limits = c(0, 160000)) + 
  labs(title = "More than 10000 items ordered", y = "number of orders") +
  coord_flip() + theme(axis.text.x = element_text(face = "plain", color = "black", size = 8))  + 
  geom_text(aes(label = n, y = n + 9000), nudge_x = 0,
nudge_y = 0, size = 2) 
```

<img src="p8105_hw3_hh2767_files/figure-markdown_github/unnamed-chunk-9-1.png" width="90%" />

``` r
ggplot(filter(count, n >= 3000 & n < 10000), aes(x = aisle, y = n)) + 
  geom_col(fill = "lightcoral", color = "navy") +  
  theme(legend.position = "bottom") + 
  labs(title = "3000 to 10000 items ordered", y = "number of orders") +
  coord_flip() + theme(axis.text.x = element_text(face = "plain", color = "black", size = 8))  + 
  geom_text(aes(label = n, y = n + 800), nudge_x = 0,
nudge_y = 0, size = 2) 
```

<img src="p8105_hw3_hh2767_files/figure-markdown_github/unnamed-chunk-9-2.png" width="90%" />

``` r
ggplot(filter(count, n < 3000), aes(x = aisle, y = n)) + 
  geom_col(fill = "lightcoral", color = "navy") +  
  theme(legend.position = "bottom") + 
  labs(title = "Less than 3000 items ordered", y = "number of orders") +
  coord_flip() + theme(axis.text.x = element_text(face = "plain", color = "black", size = 8))  + 
  geom_text(aes(label = n, y = n + 150), nudge_x = 0,
nudge_y = 0, size = 2)
```

<img src="p8105_hw3_hh2767_files/figure-markdown_github/unnamed-chunk-10-1.png" width="90%" />

As the plot shows, the aisles are devided into three groups: orderd for more than 10000 times, oedered 3000 to 10000 times, and ordered less than 3000 times. For each of the group, a graph is made with the aisles arranged according to the frequency that they are ordered.

### question 3

``` r
instacart %>% 
  filter(aisle == "baking ingredients" | aisle == "dog food care" | aisle == "packaged vegetables fruits") %>%
  group_by(aisle, product_name) %>% 
  summarize(num_items_ordered = n()) %>% 
  group_by(aisle) %>% 
  mutate(rank = min_rank(desc(num_items_ordered))) %>% 
  filter(rank == 1) %>% 
  select(aisle, `most popular item` = product_name, `number of ordered items` = num_items_ordered) %>% 
  knitr::kable()
```

| aisle                      | most popular item                             |  number of ordered items|
|:---------------------------|:----------------------------------------------|------------------------:|
| baking ingredients         | Light Brown Sugar                             |                      499|
| dog food care              | Snack Sticks Chicken & Rice Recipe Dog Treats |                       30|
| packaged vegetables fruits | Organic Baby Spinach                          |                     9784|

The table above shows that the most popular item of baking ingredients is Light Brown Sugar, of which 499 items are ordered.The most popular item of dog food care is Snack Sticks Chicken & Rice Recipe Dog Treats, of which 30 items are ordered. The most popular item of packaged vegetables fruits is Organic Baby Spinach, of which 9784 items are ordered.

### question 4

Suppose that in the instacart data, the "order\_dow" variable indicates on which week day the items were ordered, and its value 0, 1, ..., 6 denotes sunday, monday, ..., sataurday, respectively.

``` r
instacart = instacart

  instacart %>% 
  filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) %>% 
  group_by(product_name, order_dow) %>% 
  summarize(mean_order_hour = mean(order_hour_of_day)) %>% 
  spread(key = product_name, value = mean_order_hour) %>% 
  rename(weekday = order_dow) %>% 
  mutate(weekday = c("Sunday", "Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Sataurday")) %>% 
    knitr::kable(align = 'c', caption = "mean hour of the orders")
```

|  weekday  | Coffee Ice Cream | Pink Lady Apples |
|:---------:|:----------------:|:----------------:|
|   Sunday  |     13.77419     |     13.44118     |
|   Monday  |     14.31579     |     11.36000     |
|  Tuesday  |     15.38095     |     11.70213     |
| Wednesday |     15.31818     |     14.25000     |
|  Thursday |     15.21739     |     11.55172     |
|   Friday  |     12.26316     |     12.78431     |
| Sataurday |     13.83333     |     11.93750     |

problem 3
=========

### question 1

``` r
ny_noaa = ny_noaa %>% 
  separate(date, into = c("year", "month", "day"), sep = "-") %>%
  mutate(prcp = prcp / 10,
         snow = snow / 10,
         tmax = as.numeric(tmax) / 10, 
         tmin = as.numeric(tmin) / 10) %>% 
  rename(prcp_mm = prcp, 
         snow_mm = snow, 
         snwd_mm = snwd, 
         tmax_c = tmax, 
         tmin_c = tmin)

  head(ny_noaa)
```

    ## # A tibble: 6 x 9
    ##   id          year  month day   prcp_mm snow_mm snwd_mm tmax_c tmin_c
    ##   <chr>       <chr> <chr> <chr>   <dbl>   <dbl>   <int>  <dbl>  <dbl>
    ## 1 US1NYAB0001 2007  11    01         NA      NA      NA     NA     NA
    ## 2 US1NYAB0001 2007  11    02         NA      NA      NA     NA     NA
    ## 3 US1NYAB0001 2007  11    03         NA      NA      NA     NA     NA
    ## 4 US1NYAB0001 2007  11    04         NA      NA      NA     NA     NA
    ## 5 US1NYAB0001 2007  11    05         NA      NA      NA     NA     NA
    ## 6 US1NYAB0001 2007  11    06         NA      NA      NA     NA     NA

``` r
ny_noaa %>% 
  filter(!is.na(snow_mm)) %>% 
  count(snow_mm) %>% 
  arrange(-n) %>% 
  head()
```

    ## # A tibble: 6 x 2
    ##   snow_mm       n
    ##     <dbl>   <int>
    ## 1     0   2008508
    ## 2     2.5   31022
    ## 3     1.3   23095
    ## 4     5.1   18274
    ## 5     7.6   10173
    ## 6     0.8    9962

observations for temperature, precipitation, and snowfall

### question 2

``` r
  ny_noaa %>% 
  filter(month %in% c("01", "07")) %>% 
  filter(!is.na(tmax_c)) %>% 
  group_by(id, year, month) %>% 
  summarize(mean_tmax = mean(tmax_c)) %>% 
  ggplot(aes(x = year, y = mean_tmax)) +
  geom_boxplot(fill = "brown1")  + 
  facet_grid(.~month) + theme(legend.position = "bottom") + theme(axis.text.x = element_text(face = "plain", color = "black", size = 6.5, angle = 60))
```

<img src="p8105_hw3_hh2767_files/figure-markdown_github/unnamed-chunk-15-1.png" width="90%" /> The plot above is a two-panel plot. The left one shows the distribution of mean max temperature of January observed at each station, while the right one shows the distribution of mean max temperature of July observed at each station. The result shows that the mean of tempature is much lower in January than in July, and variance of the mean in January is greater than that in July. In addition, the tempuratures remain relatively stable over the years. There are some outliers almost each year, so I made another plot to find out wether those outlying data are observed from the same station or not.

``` r
  ny_noaa %>% 
  filter(month %in% c("01", "07")) %>% 
  filter(!is.na(tmax_c)) %>% 
  group_by(id, year, month) %>% 
  summarize(mean_tmax = mean(tmax_c)) %>% 
  ggplot(aes(x = year, y = mean_tmax, color = id)) +
  geom_point()  + 
  facet_grid(.~month) + theme(legend.position = "botomn") + theme(axis.text.x = element_text(face = "plain", color = "black", size = 6.5, angle = 60)) + viridis::scale_color_viridis(option = "magma", discrete = TRUE)
```

<img src="p8105_hw3_hh2767_files/figure-markdown_github/unnamed-chunk-16-1.png" width="90%" />

In the picture above, mean max temperature of each month observed at different stations are marked with different colors. From the plot, we can see that outliers in different years are from different stations. This means that there is not an area where the max temperature is always abnormal in July or in January.

### question 3

``` r
temp_plot = ny_noaa %>% 
  filter(!is.na(tmax_c) & !is.na(tmin_c)) %>% 
  ggplot(aes(x = tmax_c, y = tmin_c)) + geom_hex() + labs(title = "Max temperature VS Min temperature", x = "maximum  tempeture (°C)", y = "Minimum tempeture (°C)") 

snow_plot = ny_noaa %>% 
  select(-prcp_mm, -snwd_mm, -tmax_c, -tmin_c) %>% 
  filter(!is.na(snow_mm)) %>% 
  filter(snow_mm > 0 & snow_mm < 100) %>% 
  ggplot( aes(x = year, y = snow_mm, fill = year)) +
    geom_boxplot() + theme(legend.position = "null") + viridis::scale_fill_viridis(option = "virids", discrete = TRUE) + theme(axis.text.x = element_text(face = "plain", color = "black", size = 5, angle = 60))

temp_plot / snow_plot
```

    ## Warning in viridisLite::viridis(n, alpha, begin, end, direction, option):
    ## Option 'virids' does not exist. Defaulting to 'viridis'.

<img src="p8105_hw3_hh2767_files/figure-markdown_github/unnamed-chunk-17-1.png" width="90%" />

The graph is a two-panel plot as requested.

``` r
snow_data = ny_noaa %>% 
  select(-prcp_mm, -snwd_mm, -tmax_c, -tmin_c) %>% 
  filter(!is.na(snow_mm)) %>% 
  filter(snow_mm > 0 & snow_mm < 100)

  snow_before_1996 = ggplot(filter(snow_data, year <= 1995), aes(x = year, y = snow_mm, fill = month)) +
    geom_boxplot() + theme(legend.position = "null")
  
  snow_after_1996 = ggplot(filter(snow_data, year > 1995), aes(x = year, y = snow_mm, fill = month)) +
    geom_boxplot() + theme(legend.position = "bottom")
  snow_before_1996 / snow_after_1996 
```

<img src="p8105_hw3_hh2767_files/figure-markdown_github/unnamed-chunk-18-1.png" width="90%" />
