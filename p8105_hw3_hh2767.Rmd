---
title: "p8105_hw3_hh2767"
author: "Haoran Hu, hh2767"
date: "2018-10-09"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)

theme_set(theme_bw() + theme(legend.position = "bottom"))

library(p8105.datasets)
library(patchwork)
library(ggridges)
```

#Problem 1

##Data cleaning

```{r}
brfss = janitor::clean_names(brfss_smart2010)
colnames(brfss)[2] = "location_abbr"
colnames(brfss)[3] = "location_desc"
brfss = filter(brfss, topic == "Overall Health") %>% 
   mutate(response = factor(response, levels = c("Excellent", "Very good", "Good", "Fair", "Poor"))) %>%
  arrange(response)
```

##Answering questions

###question 1
```{r}
  filter(brfss, year == 2002) %>% 
  group_by(location_abbr) %>% 
  summarize(n_location = n_distinct(location_desc)) %>% 
  filter(n_location == 7)
```
From the result above, we know that in 2002, Connecticut, Florida, and North Carolina were observed at 7 locations.

###question 2

```{r}
brfss %>% 
  group_by(year, location_abbr) %>% 
  summarize(n_location = n_distinct(location_desc)) %>% 
  ggplot(aes(x = year, y = n_location, color = location_abbr)) +
  labs(title = "number of locations observed", y = "number of locations") +
  geom_line() + geom_point() +
  theme_bw() + viridis::scale_color_viridis(
    name = "Location", 
    discrete = TRUE
  )
```

The plot above is a “spaghetti plot” that shows the number of locations in each state from 2002 to 2010. From the plot, we can see that in most of the states, number of locations observed is relative stable, with a little fluctuation. However, there are several states that have wide fluctuation, such as Florida.

###question 3

```{r}
  brfss %>% 
  filter(location_abbr == "NY" & response == "Excellent") %>% 
  filter(year %in% c("2002", "2006", "2010")) %>% 
  group_by(year) %>% 
  summarize(`mean of prop. of "excellent" response` = round(mean(data_value, na.rm = TRUE),2), `sd of prop. of "excellent" response` = round(sd(data_value, na.rm = TRUE),2)) %>% 
  mutate(state = "NY") %>% 
  select(state, everything()) %>% 
  knitr::kable()

```

The table is created as the requeste of the question. According to the table, we can see that the mean of the proportion of "excellent" response remains stable, while its standard deviation shows a slight trend of decreasing.

###question 4

```{r fig.width=14, fig.height=12}
theme_set(theme_bw())
brfss %>% 
  group_by(year, location_abbr, response) %>% 
  summarize(mean_prop = mean(data_value, na.rm = TRUE), sample_size = sum(sample_size)) %>% 
  ggplot(aes(x = year, y = mean_prop, color = location_abbr)) + geom_point(aes(size = sample_size), alpha = .5) + geom_smooth(se = FALSE) + labs(title = "proportion of each response in each state") + 
  facet_grid(~ response) +  viridis::scale_color_viridis(
    name = "Location", 
    discrete = TRUE
  )
```

The figure above is created as request of the question.The figure shows that the majority of people in each state responded "Excellent", "Very good", or "Good". What is interesting is that in each state, the proportion of each response is largely the same. In addition, the proportion of each response remains stable over the years.

#Problem 2

###Description of the dataset
The "instacart" dataset is a `r nrow(instacart)`(rows) * `r ncol(instacart)`(columns) dataset. Each row of the data indicates the following informations: the id of the order, which kind of and how many of the products is ordered, whether the product is reordered by the customer or not, when is the order, what department dose the produce belong to, etc. Each column variable indicates one of the characteristics of the orders. For example, the first row is a record showing the following information: the order id is "1", and is ordered by the user whose id is "112108". The ordered product is "Bulgarian Yogurt", which is in "Yogurt" aisle and "dairy eggs" department. They are reordered by the customer, and 4 of them were ordered this time. The order was on thursday 10:00, and it has been 9 days since the product was ordered last time.

###question 1

```{r}
 count = instacart %>% 
  count(aisle) %>% 
   arrange(-n)
```

There are `r nrow(count)` aisles, and "`r count[1,1]`" is ordered for the most times.

###question 2

First, in order to arrange the aisles according to the frequency that they are ordered when making the graph, I need to first turn the aisles in to ordered factor variables.
```{r}
count$aisle = factor(count$aisle, levels = count$aisle)
```

Then, I can begin to make the graph.

```{r fig.width=17, fig.height=500, fig.align='center'}
order_over10k = ggplot(filter(count, n >= 10000), aes(x = aisle, y = n, fill = aisle)) + 
  geom_col() +  
  theme(legend.position = "bottom") + 
  scale_x_discrete(breaks = NULL) + 
  scale_y_continuous( limits = c(0, 160000)) + 
  labs(title = "More than 10000 items ordered", y = "number of orders") + 
  viridis::scale_fill_viridis( discrete = TRUE)

order_3k_10K = ggplot(filter(count, n >= 3000 & n < 10000), aes(x = aisle, y = n, fill = aisle)) + 
  geom_col() +  
  theme(legend.position = "bottom") + 
  scale_x_discrete(breaks = NULL) + 
  labs(title = "3000 to 10000 items ordered", y = "number of orders") + 
  viridis::scale_fill_viridis( discrete = TRUE)

ordre_less3k = ggplot(filter(count, n < 3000), aes(x = aisle, y = n, fill = aisle)) + 
  geom_col() +  
  theme(legend.position = "bottom") + 
  scale_x_discrete(breaks = NULL) + 
  labs(title = "Less than 3000 items ordered", y = "number of orders") +
  viridis::scale_fill_viridis( discrete = TRUE)

(order_over10k + order_3k_10K) / ordre_less3k

```

We can also make the graph in the following way.

```{r fig.width = 10, fig.asp = .8}
ggplot(filter(count, n >= 10000), aes(x = aisle, y = n)) + 
  geom_col(fill = "lightcoral", color = "navy") +  
  theme(legend.position = "bottom") + 
  scale_y_continuous( limits = c(0, 160000)) + 
  labs(title = "More than 10000 items ordered", y = "number of orders") +
  coord_flip() + theme(axis.text.x = element_text(face = "plain", color = "black", size = 8))  + 
  geom_text(aes(label = n, y = n + 9000), nudge_x = 0,
nudge_y = 0, size = 2) 

ggplot(filter(count, n >= 3000 & n < 10000), aes(x = aisle, y = n)) + 
  geom_col(fill = "lightcoral", color = "navy") +  
  theme(legend.position = "bottom") + 
  labs(title = "3000 to 10000 items ordered", y = "number of orders") +
  coord_flip() + theme(axis.text.x = element_text(face = "plain", color = "black", size = 8))  + 
  geom_text(aes(label = n, y = n + 800), nudge_x = 0,
nudge_y = 0, size = 2) 

```

```{r fig.width = 10, fig.asp = .8}
ggplot(filter(count, n < 3000), aes(x = aisle, y = n)) + 
  geom_col(fill = "lightcoral", color = "navy") +  
  theme(legend.position = "bottom") + 
  labs(title = "Less than 3000 items ordered", y = "number of orders") +
  coord_flip() + theme(axis.text.x = element_text(face = "plain", color = "black", size = 8))  + 
  geom_text(aes(label = n, y = n + 150), nudge_x = 0,
nudge_y = 0, size = 2)

```


As the plot shows, the aisles are devided into three groups: orderd for more than 10000 times, oedered 3000 to 10000 times, and ordered less than 3000 times. For each of the group, a graph is made with the aisles arranged according to the frequency that they are ordered. As the graph shows, number of items ordered in different aisles varies greatly. For the majotiry of the aisles, several hundreds to several thousands items are ordered. However, in aisles like fresh fruits and fresh vegetables, hundreds of thousands items were ordered.

###question 3

```{r}
instacart %>% 
  filter(aisle == "baking ingredients" | aisle == "dog food care" | aisle == "packaged vegetables fruits") %>%
  group_by(aisle, product_name) %>% 
  summarize(num_items_ordered = n()) %>% 
  group_by(aisle) %>% 
  mutate(rank = min_rank(desc(num_items_ordered))) %>% 
  filter(rank == 1) %>% 
  select(aisle, `most popular item` = product_name, `number of ordered items` = num_items_ordered) %>% 
  knitr::kable()
```

The table above shows that the most popular item of baking ingredients is Light Brown Sugar, of which 499 items are ordered.The most popular item of dog food care is Snack Sticks Chicken & Rice Recipe Dog Treats, of which 30 items are ordered. The most popular item of packaged vegetables fruits is Organic Baby Spinach, of which 9784 items are ordered.

###question 4

Suppose that in the instacart data, the "order_dow" variable indicates on which week day the items were ordered, and its value 0, 1, ..., 6 denotes sunday, monday, ..., sataurday, respectively.

```{r}
instacart = instacart

 a = instacart %>% 
  filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) %>% 
  group_by(product_name, order_dow) %>% 
  summarize(mean_order_hour = round(mean(order_hour_of_day),2)) %>% 
    rename(weekday = order_dow) %>% 
  mutate(weekday = c("Sunday", "Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Sataurday")) %>% 
   mutate(weekday = factor(weekday, levels = c("Sunday", "Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Sataurday"))) %>% 
    mutate(hour = floor(mean_order_hour), min = round(60 * (mean_order_hour - floor(mean_order_hour)))) %>% 
   mutate(`mean hour of the orders` = paste(hour, ":", min)) %>% 
   select(-mean_order_hour, -hour , -min) %>% 
  spread(key = weekday, value = `mean hour of the orders`) %>% 
    knitr::kable(align = 'c', caption = "mean hour of the orders")
  
```

This table shows mean hour of the orders in each weekday.

#problem 3

###description of the dataset
The 

###question 1

```{r}
ny_noaa = ny_noaa %>% 
  separate(date, into = c("year", "month", "day"), sep = "-") %>%
  mutate(prcp = prcp / 10,
         snow = snow / 10,
         tmax = as.numeric(tmax) / 10, 
         tmin = as.numeric(tmin) / 10) %>% 
  rename(prcp_mm = prcp, 
         snow_mm = snow, 
         snwd_mm = snwd, 
         tmax_c = tmax, 
         tmin_c = tmin)

snow_data = ny_noaa #used for boxplot in the last question

ny_noaa$month = plyr::mapvalues(ny_noaa$month, 
          from = c("01", "02", "03", "04", "05", "06", "07", "08", "09", "10", "11", "12"), 
          to = c("January","Feburary","March", "April", "May", "June", "July", "August", "September", "October", "November", "December"))

ny_noaa %>% 
mutate(month = factor(month, levels = c("January","Feburary","March", "April", "May", "June", "July", "August", "September", "October", "November", "December"))) 

  head(ny_noaa)

```

```{r}

ny_noaa %>% 
  filter(!is.na(snow_mm)) %>% 
  count(snow_mm) %>% 
  arrange(-n) %>% 
  head()
```
observations for temperature, precipitation, and snowfall 

###question 2

```{r fig.width=10, fig.height=20}
  ny_noaa %>% 
  filter(month %in% c("January", "July")) %>% 
  filter(!is.na(tmax_c)) %>% 
  group_by(id, year, month) %>% 
  summarize(mean_tmax = mean(tmax_c)) %>% 
  ggplot(aes(x = year, y = mean_tmax)) +
  geom_boxplot(fill = "brown1")  + 
  facet_grid(.~month) + theme(legend.position = "bottom") + theme(axis.text.x = element_text(face = "plain", color = "black", size = 6.5, angle = 60))
```
The plot above is a two-panel plot. The left one shows the distribution of mean max temperature of January observed at each station, while the right one shows the distribution of mean max temperature of July observed at each station. The result shows that the mean of tempature is much lower in January than in July, and variance of the mean in January is greater than that in July. In addition, the tempuratures remain relatively stable over the years. There are some outliers almost each year, so I made another plot to find out wether those outlying data are observed from the same station or not.

```{r}
  ny_noaa %>% 
  filter(month %in% c("January", "July")) %>% 
  filter(!is.na(tmax_c)) %>% 
  group_by(id, year, month) %>% 
  summarize(mean_tmax = mean(tmax_c)) %>% 
  ggplot(aes(x = year, y = mean_tmax, color = id)) +
  geom_point()  +  labs(
    title = "Average Maximum temperature in January and July (by stations)",
    x = "Year",
    y = "Average maxiumum temperature (°C)",
    caption = "Different color of the points means different stations"
  ) +
  facet_grid(.~month) + theme(legend.position = "botomn") + theme(axis.text.x = element_text(face = "plain", color = "black", size = 6.5, angle = 60)) + viridis::scale_color_viridis(option = "magma", discrete = TRUE)
```

In the picture above, mean max temperature of each month observed at different stations are marked with different colors. From the plot, we can see that outliers in different years are from different stations. This means that there is not an area where the max temperature is always abnormal in July or in January.

###question 3

```{r fig.width = 10, fig.asp = .8}
temp_plot = ny_noaa %>% 
  filter(!is.na(tmax_c) & !is.na(tmin_c)) %>% 
  ggplot(aes(x = tmax_c, y = tmin_c)) + geom_hex() + labs(title = "Max temperature VS Min temperature", x = "maximum  tempeture (°C)", y = "Minimum tempeture (°C)") 

snow_plot = ny_noaa %>% 
  select(-prcp_mm, -snwd_mm, -tmax_c, -tmin_c) %>% 
  filter(!is.na(snow_mm)) %>% 
  filter(snow_mm > 0 & snow_mm < 100) %>% 
  ggplot( aes(x = year, y = snow_mm)) +
    geom_boxplot(fill = "blue") + theme(legend.position = "null") + theme(axis.text.x = element_text(face = "plain", color = "black", size = 5, angle = 60))

temp_plot / snow_plot
```

The graph is a two-panel plot as requested.

```{r fig.width = 15, fig.asp = .9}

snow_data = snow_data %>% 
  select(-prcp_mm, -snwd_mm, -tmax_c, -tmin_c) %>% 
  filter(!is.na(snow_mm)) %>% 
  filter(snow_mm > 0 & snow_mm < 100)

  snow_before_1996 = ggplot(filter(snow_data, year <= 1995), aes(x = year, y = snow_mm, fill = month)) +
    geom_boxplot() + theme(legend.position = "null")
  
  snow_after_1996 = ggplot(filter(snow_data, year > 1995), aes(x = year, y = snow_mm, fill = month)) +
    geom_boxplot() + theme(legend.position = "bottom")
  snow_before_1996 / snow_after_1996 
```

